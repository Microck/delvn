---
phase: 04-prioritization-reporting
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/prioritization/__init__.py
  - src/prioritization/scoring.py
  - src/agents/prioritizer_agent.py
  - tests/test_prioritization_scoring.py
autonomous: true
must_haves:
  truths:
    - "Threats are scored HIGH/MEDIUM/LOW/NONE based on user stack"
    - "Prioritizer produces a ranked list ready for reporting"
  artifacts:
    - path: "src/prioritization/scoring.py"
      provides: "Relevance scoring logic"
    - path: "src/agents/prioritizer_agent.py"
      provides: "Prioritizer agent (Cosmos -> scored threats)"
  key_links:
    - from: "src/agents/prioritizer_agent.py"
      to: "src/config/user_stack.py"
      via: "load_user_stack"
      pattern: "load_user_stack"
---

<objective>
Implement the Prioritizer Agent and relevance scoring based on the user's tech stack.

Purpose: Convert correlated threats into what matters to THIS user.
Output: Scoring logic + prioritizer agent.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
  @.planning/REQUIREMENTS.md
  @.planning/phases/04-prioritization-reporting/04-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement relevance scoring function</name>
  <files>
src/prioritization/__init__.py
src/prioritization/scoring.py
  </files>
  <action>
Create `src/prioritization/scoring.py`:
- Define `Relevance` enum: HIGH/MEDIUM/LOW/NONE
- Implement `score_relevance(threat: UnifiedThreat, stack: UserStack) -> (Relevance, list[str])`

Rules (simple and demo-friendly):
- Match against `threat.content_text()` using keyword contains
- If matches a product keyword and severity >= 7 or has "exploited" tag -> HIGH
- Product match without above -> MEDIUM
- Weak keyword match -> LOW
- Otherwise NONE

Always return reason strings explaining why the score was assigned.
  </action>
  <verify>python3 -c "from prioritization.scoring import score_relevance"</verify>
  <done>Scoring is importable</done>
</task>

<task type="auto">
  <name>Task 2: Implement Prioritizer Agent (load -> score -> rank)</name>
  <files>src/agents/prioritizer_agent.py</files>
  <action>
Create `src/agents/prioritizer_agent.py` with `run_prioritization()`:
- Load user stack from `src/config/user_stack.yaml`
- Load recent threats (and optionally correlations) from Cosmos
- Compute relevance + reasons per threat
- Return a ranked list (HIGH first, then by severity desc)

Do not generate the report here; return structured data for the reporter.
  </action>
  <verify>python3 -c "from agents.prioritizer_agent import run_prioritization"</verify>
  <done>Prioritizer agent entrypoint is importable</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for relevance scoring</name>
  <files>tests/test_prioritization_scoring.py</files>
  <action>
Add tests for:
- product keyword hit -> MEDIUM
- product keyword + high severity -> HIGH
- no match -> NONE
- reasons list is non-empty when not NONE
  </action>
  <verify>python3 -m pytest -q</verify>
  <done>Prioritization tests pass</done>
</task>

</tasks>

<verification>
- `python3 -m pytest -q` passes
</verification>

<success_criteria>
- Given the demo stack, at least one CVE-related threat becomes HIGH in demo dataset
</success_criteria>

<output>
After completion, create `.planning/phases/04-prioritization-reporting/04-02-SUMMARY.md`
</output>
