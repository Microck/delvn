---
phase: 03-correlation
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/models/correlation.py
  - src/correlation/__init__.py
  - src/correlation/scoring.py
  - src/correlation/matcher.py
  - tests/test_correlation_scoring.py
autonomous: true
must_haves:
  truths:
    - "Similar threats can be proposed as correlation candidates"
    - "Each proposed link has an explainable confidence score"
  artifacts:
    - path: "src/models/correlation.py"
      provides: "Correlation link model (source/target/confidence/reasons)"
    - path: "src/correlation/scoring.py"
      provides: "Confidence scoring function with tests"
    - path: "src/correlation/matcher.py"
      provides: "Candidate matching logic (vector results -> scored links)"
  key_links:
    - from: "src/correlation/matcher.py"
      to: "src/storage/search.py"
      via: "vector query results"
      pattern: "search"
---

<objective>
Define correlation links and implement confidence scoring + candidate matching logic.

Purpose: Turn vector similarity into actionable, explainable correlations.
Output: Correlation model + matcher + tests.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/03-correlation/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add correlation link model</name>
  <files>src/models/correlation.py</files>
  <action>
Create `src/models/correlation.py` with Pydantic models:
- `CorrelationLink` fields:
  - `id` (string; deterministic: `corr:{source_id}->{target_id}`)
  - `source_id`, `target_id`
  - `confidence` (0..1 float)
  - `reasons` (list[str])
  - `created_at` (datetime)
- Optional: `similarity` raw score if available.

Keep it generic (works for CVE<->indicator, CVE<->news, etc.).
  </action>
  <verify>python3 -c "from models.correlation import CorrelationLink; CorrelationLink.model_json_schema()"</verify>
  <done>CorrelationLink schema generation works</done>
</task>

<task type="auto">
  <name>Task 2: Implement scoring + candidate matcher</name>
  <files>
src/correlation/__init__.py
src/correlation/scoring.py
src/correlation/matcher.py
  </files>
  <action>
Create `src/correlation/scoring.py` with `score_correlation(*, similarity: float, shared_terms: int, same_source: bool) -> (confidence: float, reasons: list[str])`.

Rules (simple + explainable):
- similarity contributes most to confidence
- shared_terms (e.g., CVE ids / indicator values present in both content_text) boosts confidence
- same_source should reduce confidence slightly (avoid self-correlation dominating)

Create `src/correlation/matcher.py`:
- Take a `UnifiedThreat` + a list of vector search hits
- Compute shared term counts (basic token overlap + explicit CVE/IOC regex matches)
- Output a list of `CorrelationLink` objects.
  </action>
  <verify>python3 -c "from correlation.scoring import score_correlation"</verify>
  <done>Scoring and matcher functions are importable</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for scoring behavior and reasons</name>
  <files>tests/test_correlation_scoring.py</files>
  <action>
Add tests asserting:
- higher similarity -> higher confidence
- shared terms boost confidence and add reason strings
- confidence clamps to [0, 1]
  </action>
  <verify>python3 -m pytest -q</verify>
  <done>Correlation scoring tests pass</done>
</task>

</tasks>

<verification>
- `python3 -m pytest -q` passes
</verification>

<success_criteria>
- Correlation links are explainable (reasons list) and scored consistently
</success_criteria>

<output>
After completion, create `.planning/phases/03-correlation/03-02-SUMMARY.md`
</output>
